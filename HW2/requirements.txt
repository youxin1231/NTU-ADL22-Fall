#
# This file is autogenerated by pip-compile with python 3.8
# To update, run:
#
#    pip-compile requirements.in
#
absl-py==1.3.0
    # via
    #   tensorboard
    #   tensorflow
accelerate==0.13.0
    # via -r requirements.in
aiohttp==3.8.3
    # via
    #   datasets
    #   fsspec
aiosignal==1.2.0
    # via aiohttp
astunparse==1.6.3
    # via tensorflow
async-timeout==4.0.2
    # via aiohttp
attrs==22.1.0
    # via aiohttp
cachetools==5.2.0
    # via google-auth
certifi==2022.9.24
    # via requests
charset-normalizer==2.1.1
    # via
    #   aiohttp
    #   requests
click==8.1.3
    # via nltk
datasets==2.5.2
    # via
    #   -r requirements.in
    #   evaluate
dill==0.3.5.1
    # via
    #   datasets
    #   evaluate
    #   multiprocess
evaluate==0.3.0
    # via -r requirements.in
filelock==3.8.0
    # via
    #   huggingface-hub
    #   transformers
flatbuffers==22.10.26
    # via tensorflow
frozenlist==1.3.1
    # via
    #   aiohttp
    #   aiosignal
fsspec[http]==2022.10.0
    # via
    #   datasets
    #   evaluate
gast==0.4.0
    # via tensorflow
google-auth==2.14.0
    # via
    #   google-auth-oauthlib
    #   tensorboard
google-auth-oauthlib==0.4.6
    # via tensorboard
google-pasta==0.2.0
    # via tensorflow
grpcio==1.50.0
    # via
    #   tensorboard
    #   tensorflow
h5py==3.7.0
    # via tensorflow
huggingface-hub==0.10.1
    # via
    #   datasets
    #   evaluate
    #   transformers
idna==3.4
    # via
    #   requests
    #   yarl
importlib-metadata==5.0.0
    # via markdown
joblib==1.2.0
    # via
    #   nltk
    #   scikit-learn
keras==2.10.0
    # via tensorflow
keras-preprocessing==1.1.2
    # via tensorflow
libclang==14.0.6
    # via tensorflow
markdown==3.4.1
    # via tensorboard
markupsafe==2.1.1
    # via werkzeug
multidict==6.0.2
    # via
    #   aiohttp
    #   yarl
multiprocess==0.70.13
    # via
    #   -r requirements.in
    #   datasets
    #   evaluate
nltk==3.7
    # via -r requirements.in
numpy==1.23.4
    # via
    #   -r requirements.in
    #   accelerate
    #   datasets
    #   evaluate
    #   h5py
    #   keras-preprocessing
    #   opt-einsum
    #   pandas
    #   pyarrow
    #   scikit-learn
    #   scipy
    #   tensorboard
    #   tensorflow
    #   transformers
oauthlib==3.2.2
    # via requests-oauthlib
opt-einsum==3.3.0
    # via tensorflow
packaging==21.3
    # via
    #   accelerate
    #   datasets
    #   evaluate
    #   huggingface-hub
    #   tensorflow
    #   transformers
pandas==1.5.1
    # via
    #   -r requirements.in
    #   datasets
    #   evaluate
protobuf==3.19.6
    # via
    #   -r requirements.in
    #   tensorboard
    #   tensorflow
psutil==5.9.3
    # via accelerate
pyarrow==10.0.0
    # via datasets
pyasn1==0.4.8
    # via
    #   pyasn1-modules
    #   rsa
pyasn1-modules==0.2.8
    # via google-auth
pyparsing==3.0.9
    # via packaging
python-dateutil==2.8.2
    # via pandas
pytz==2022.6
    # via pandas
pyyaml==6.0
    # via
    #   accelerate
    #   huggingface-hub
    #   transformers
regex==2022.10.31
    # via
    #   nltk
    #   transformers
requests==2.28.1
    # via
    #   datasets
    #   evaluate
    #   fsspec
    #   huggingface-hub
    #   requests-oauthlib
    #   responses
    #   tensorboard
    #   transformers
requests-oauthlib==1.3.1
    # via google-auth-oauthlib
responses==0.18.0
    # via
    #   datasets
    #   evaluate
rsa==4.9
    # via google-auth
scikit-learn==1.1.2
    # via -r requirements.in
scipy==1.9.3
    # via scikit-learn
sentencepiece==0.1.97
    # via -r requirements.in
six==1.16.0
    # via
    #   astunparse
    #   google-auth
    #   google-pasta
    #   grpcio
    #   keras-preprocessing
    #   python-dateutil
    #   tensorflow
tensorboard==2.10.1
    # via tensorflow
tensorboard-data-server==0.6.1
    # via tensorboard
tensorboard-plugin-wit==1.8.1
    # via tensorboard
tensorflow==2.10.0
    # via -r requirements.in
tensorflow-estimator==2.10.0
    # via tensorflow
tensorflow-io-gcs-filesystem==0.27.0
    # via tensorflow
termcolor==2.1.0
    # via tensorflow
threadpoolctl==3.1.0
    # via scikit-learn
tokenizers==0.12.1
    # via transformers
torch==1.12.1
    # via
    #   -r requirements.in
    #   accelerate
tqdm==4.64.1
    # via
    #   -r requirements.in
    #   datasets
    #   evaluate
    #   huggingface-hub
    #   nltk
    #   transformers
transformers==4.22.2
    # via -r requirements.in
typing-extensions==4.4.0
    # via
    #   huggingface-hub
    #   tensorflow
    #   torch
urllib3==1.26.12
    # via
    #   requests
    #   responses
werkzeug==2.2.2
    # via tensorboard
wheel==0.37.1
    # via
    #   astunparse
    #   tensorboard
wrapt==1.14.1
    # via tensorflow
xxhash==3.1.0
    # via
    #   datasets
    #   evaluate
yarl==1.8.1
    # via aiohttp
zipp==3.10.0
    # via importlib-metadata

# The following packages are considered to be unsafe in a requirements file:
# setuptools
